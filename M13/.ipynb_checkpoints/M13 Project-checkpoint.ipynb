{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "# Analytics Programming: Module 13\n",
    "## Natural Language Toolkit (NLTK)\n",
    "#### Alan Leidner Dec 1, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will perform a Sentiment Analysis on Movie Reviews. This is a collection of text called a corpus, which the Natural Language Toolkit (nltk) library provides. The nltk library also provides a number of tools to analyze this curpos, which I will demonstrate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will import NLTK's movie_reviews corpus. To do this I must first make sure the python notebook has the `nltk` library imported, and the 'movie_reviews' curpos is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/leidner/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful function of `nltk` is `readme()`. This funtion returns the contents of the corpus README file, if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity Dataset Version 2.0\n",
      "Bo Pang and Lillian Lee\n",
      "\n",
      "http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
      "\n",
      "Distributed with NLTK with permission from the authors.\n",
      "\n",
      "=======\n",
      "\n",
      "Introduction\n",
      "\n",
      "This README v2.0 (June, 2004) for the v2.0 polarity dataset comes from\n",
      "the URL http://www.cs.cornell.edu/people/pabo/movie-review-data .\n",
      "\n",
      "=======\n",
      "\n",
      "What's New -- June, 2004\n",
      "\n",
      "This dataset represents an enhancement of the review corpus v1.0\n",
      "described in README v1.1: it contains more reviews, and labels were\n",
      "created with an improved rating-extraction system.\n",
      "\n",
      "=======\n",
      "\n",
      "Citation Info \n",
      "\n",
      "This data was first used in Bo Pang and Lillian Lee,\n",
      "``A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization \n",
      "Based on Minimum Cuts'',  Proceedings of the ACL, 2004.\n",
      "\n",
      "@InProceedings{Pang+Lee:04a,\n",
      "  author =       {Bo Pang and Lillian Lee},\n",
      "  title =        {A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts},\n",
      "  booktitle =    \"Proceedings of the ACL\",\n",
      "  year =         2004\n",
      "}\n",
      "\n",
      "=======\n",
      "\n",
      "Data Format Summary \n",
      "\n",
      "- review_polarity.tar.gz: contains this readme and  data used in\n",
      "  the experiments described in Pang/Lee ACL 2004.\n",
      "\n",
      "  Specifically:\n",
      "\n",
      "  Within the folder \"txt_sentoken\" are the 2000 processed down-cased\n",
      "  text files used in Pang/Lee ACL 2004; the names of the two\n",
      "  subdirectories in that folder, \"pos\" and \"neg\", indicate the true\n",
      "  classification (sentiment) of the component files according to our\n",
      "  automatic rating classifier (see section \"Rating Decision\" below).\n",
      "\n",
      "  File names consist of a cross-validation tag plus the name of the\n",
      "  original html file.  The ten folds used in the Pang/Lee ACL 2004 paper's\n",
      "  experiments were:\n",
      "\n",
      "     fold 1: files tagged cv000 through cv099, in numerical order\n",
      "     fold 2: files tagged cv100 through cv199, in numerical order     \n",
      "     ...\n",
      "     fold 10: files tagged cv900 through cv999, in numerical order\n",
      "\n",
      "  Hence, the file neg/cv114_19501.txt, for example, was labeled as\n",
      "  negative, served as a member of fold 2, and was extracted from the\n",
      "  file 19501.html in polarity_html.zip (see below).\n",
      "\n",
      "  Each line in each text file corresponds to a single sentence, as\n",
      "  determined by Adwait Ratnaparkhi's sentence boundary detector\n",
      "  MXTERMINATOR.\n",
      " \n",
      "  Preliminary steps were taken to remove rating information from the\n",
      "  text files, but only the rating information upon which the rating\n",
      "  decision was based is guaranteed to have been removed. Thus, if the\n",
      "  original review contains several instances of rating information,\n",
      "  potentially given in different forms, those not recognized as valid\n",
      "  ratings remain part of the review text.\n",
      "\t\n",
      "- polarity_html.zip: The original source files from which the\n",
      "  processed, labeled, and (randomly) selected data in\n",
      "  review_polarity.tar.gz was derived.\n",
      "\n",
      "  Specifically:  \n",
      "\n",
      "  This data consists of unprocessed, unlabeled html files from the\n",
      "  IMDb archive of the rec.arts.movies.reviews newsgroup,\n",
      "  http://reviews.imdb.com/Reviews. The files in review_polarity.tar.gz\n",
      "  represent a processed subset of these files. \n",
      "\n",
      "=======\n",
      "\n",
      "Rating Decision (Appendix A)\n",
      "\n",
      "This section describes how we determined whether a review was positive\n",
      "or negative.\n",
      "\n",
      "The original html files do not have consistent formats -- a review may\n",
      "not have the author's rating with it, and when it does, the rating can\n",
      "appear at different places in the file in different forms.  We only\n",
      "recognize some of the more explicit ratings, which are extracted via a\n",
      "set of ad-hoc rules.  In essence, a file's classification is determined\n",
      "based on the first rating we were able to identify.\n",
      "\n",
      "\n",
      "- In order to obtain more accurate rating decisions, the maximum\n",
      "\trating must be specified explicitly, both for numerical ratings\n",
      "\tand star ratings.  (\"8/10\", \"four out of five\", and \"OUT OF\n",
      "\t****: ***\" are examples of rating indications we recognize.)\n",
      "\n",
      "- With a five-star system (or compatible number systems):\n",
      "\tthree-and-a-half stars and up are considered positive, \n",
      "\ttwo stars and below are considered negative.\n",
      "- With a four-star system (or compatible number system):\n",
      "\tthree stars and up are considered positive, \n",
      "\tone-and-a-half stars and below are considered negative.  \n",
      "- With a letter grade system:\n",
      "\tB or above is considered positive,\n",
      "\tC- or below is considered negative.\n",
      "\n",
      "We attempted to recognize half stars, but they are specified in an\n",
      "especially free way, which makes them difficult to recognize.  Hence,\n",
      "we may lose a half star very occasionally; but this only results in 2.5\n",
      "stars in five star system being categorized as negative, which is \n",
      "still reasonable.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.readme())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will take a look at the general shape of the 'movie_reviews' corpus. To do so, I will use the `fileids()` function to generate a list of all of the file names in the corpus (I will turn these into a list to use more easily). I will then use the `len()` function to quickly count the number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr = movie_reviews.fileids() \n",
    "len(mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the `categories()` function to print the categories found in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the text file names. I will look at the first and last four by calling out their positions on the list we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt',\n",
       " 'pos/cv995_21821.txt',\n",
       " 'pos/cv996_11592.txt',\n",
       " 'pos/cv997_5046.txt',\n",
       " 'pos/cv998_14111.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr[1:5] + mr[-5:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will print the raw text from a negative review, and then a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the happy bastard's quick movie review \n",
      "damn that y2k bug . \n",
      "it's got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . \n",
      "little do they know the power within . . . \n",
      "going for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . \n",
      "we don't know why the crew was really out in the middle of nowhere , we don't know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don't know why donald sutherland is stumbling around drunkenly throughout . \n",
      "here , it's just \" hey , let's chase these people around with some robots \" . \n",
      "the acting is below average , even from the likes of curtis . \n",
      "you're more likely to get a kick out of her work in halloween h20 . \n",
      "sutherland is wasted and baldwin , well , he's acting like a baldwin , of course . \n",
      "the real star here are stan winston's robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone's brain . \n",
      "so , if robots and body parts really turn you on , here's your movie . \n",
      "otherwise , it's pretty much a sunken ship of a movie . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.raw('neg/cv001_19502.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steven spielberg's second epic film on world war ii is an unquestioned masterpiece of film . \n",
      "spielberg , ever the student on film , has managed to resurrect the war genre by producing one of its grittiest , and most powerful entries . \n",
      "he also managed to cast this era's greatest answer to jimmy stewart , tom hanks , who delivers a performance that is nothing short of an astonishing miracle . \n",
      "for about 160 out of its 170 minutes , \" saving private ryan \" is flawless . \n",
      "literally . \n",
      "the plot is simple enough . \n",
      "after the epic d-day invasion ( whose sequences are nothing short of spectacular ) , capt . john miller ( hanks ) and his team are forced to search for a pvt . \n",
      "james ryan ( damon ) , whose brothers have all died in battle . \n",
      "once they find him , they are to bring him back for immediate discharge so that he can go home . \n",
      "accompanying miller are his crew , played with astonishing perfection by a group of character actors that are simply sensational . \n",
      "barry pepper , adam goldberg , vin diesel , giovanni ribisi , davies , and burns are the team sent to find one man , and bring him home . \n",
      "the battle sequences that bookend the film are extraordinary . \n",
      "literally . \n",
      "there is nothing in film that has ever been recorded that will prepare you for the sheer onslaught of terrorizing violence in the film's first 20 minutes . \n",
      "spielberg films almost the entire movie without music , leaving it up to the characters to generate emotion , and they do to perfection . \n",
      "the sequences in france , all of them , beginning with the battle and ending with the battle , are fabulous , especially the dialogues between the men as they walk through the hills and countrysides , trying to save private ryan . \n",
      "there are no words i can use to describe the true horror and power of these sequences . \n",
      "this is what coppola was looking for in \" apocalypse now \" , but couldn't create . \n",
      "the sheer horror of these sequences all but condemn war . \n",
      "the performance by hanks as the leader of this gang is also extraordinary . \n",
      "he is head and shoulders above of the rest of the actors in the world , with his comic timing , dramatic flair , his quiet emotion that stirs an entire nation to tears . \n",
      "hanks is this country's finest actor , and he proves it here . \n",
      "however , spielberg almost destroys his own masterpiece . \n",
      "with a chance to make it the one of the greatest films of all time , spielberg creates 10 minutes of purely worthless film . \n",
      "the sequence involving army chief-of-stafff george marshall and mrs . ryan is decent , but doesn't hold up to the rest of the film , relying on wartime cliches to power it . \n",
      "but that is forgivable . \n",
      "what isn't is the bookends of the film , the cemetary sequences . \n",
      "the first one is quite good , a decent introduction into the lives of these men . \n",
      "the last sequence is atrocious . \n",
      "the forced emotion , accompanied by a ridiculous piece of music , is simply horrible compared to the rest of the magical film . \n",
      "these flaws are what downgrade \" ryan \" from the greatest film of our era , to the greatest war film of our era . \n",
      "spielberg should have trusted his own material , and he should have trusted hanks to deliver the most chilling line of the movie , to end his masterpiece right there . \n",
      "the use of the flag , though patriotic , is in contrast to the movie's theme . \n",
      "the power of the bulk of the film , however , is astonishing . \n",
      "spielberg has truly made a wondrous work of art , that persists even after first viewing of the film , is extraordinary . \n",
      "this is the film of the year . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.raw('pos/cv998_14111.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
